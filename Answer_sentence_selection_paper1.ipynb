{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-547ER22Qr6"
      },
      "outputs": [],
      "source": [
        "#A Study on Efficiency, Accuracy and Document Structure for Answer Sentence Selection\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "QUESTION_LEN = 23\n",
        "CANDIDATE_LEN = 503"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuFyVPpK2ZOU",
        "outputId": "1428860f-357d-472e-b0c2-a5d73e1ca4a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/Colab Notebooks/NLP-Project/data\"\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODvIzbzAplgh",
        "outputId": "62932a07-4053-4fa0-f559-0e182be17636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/NLP-Project/data\n",
            "23-50-test_maps.pkl   qc_embeddings_dev_paper1.pkl    test_mrrs.pkl\n",
            "23-50-test_mrrs.pkl   qc_embeddings_paper1.pkl        train_maps.pkl\n",
            "23-50-train_maps.pkl  qc_embeddings_test_paper1.pkl   train_mrrs.pkl\n",
            "23-50-train_mrrs.pkl  qc_embeddings_train_paper1.pkl  \u001b[0m\u001b[01;34mWikiQACorpus\u001b[0m/\n",
            "numberbatch-en.txt    test_maps.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN91w0gi2Qr-"
      },
      "source": [
        "## Number Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LSeBMhl2QsA",
        "outputId": "55a5a58c-3e43-43ce-ccfb-11888ce7767b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wordfreq in /usr/local/lib/python3.7/dist-packages (3.0.3)\n",
            "Requirement already satisfied: langcodes>=3.0 in /usr/local/lib/python3.7/dist-packages (from wordfreq) (3.3.0)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.7/dist-packages (from wordfreq) (1.0.4)\n",
            "Requirement already satisfied: regex>=2021.7.6 in /usr/local/lib/python3.7/dist-packages (from wordfreq) (2022.6.2)\n",
            "Requirement already satisfied: ftfy>=6.1 in /usr/local/lib/python3.7/dist-packages (from wordfreq) (6.1.1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy>=6.1->wordfreq) (0.2.5)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This Python module provides just the code from the 'conceptnet5' module that\n",
        "you need to represent terms, possibly with multiple words, as ConceptNet URIs.\n",
        "\n",
        "It depends on 'wordfreq', a Python 3 library, so it can tokenize multilingual\n",
        "text consistently: https://pypi.org/project/wordfreq/\n",
        "\n",
        "Example:\n",
        "\n",
        ">>> standardized_uri('es', 'ayudar')\n",
        "'/c/es/ayudar'\n",
        ">>> standardized_uri('en', 'a test phrase')\n",
        "'/c/en/test_phrase'\n",
        ">>> standardized_uri('en', '24 hours')\n",
        "'/c/en/##_hours'\n",
        "\"\"\"\n",
        "!pip install wordfreq\n",
        "import wordfreq\n",
        "import re\n",
        "\n",
        "\n",
        "# English-specific stopword handling\n",
        "STOPWORDS = ['the', 'a', 'an']\n",
        "DROP_FIRST = ['to']\n",
        "DOUBLE_DIGIT_RE = re.compile(r'[0-9][0-9]')\n",
        "DIGIT_RE = re.compile(r'[0-9]')\n",
        "\n",
        "\n",
        "def standardized_uri(language, term):\n",
        "    \"\"\"\n",
        "    Get a URI that is suitable to label a row of a vector space, by making sure\n",
        "    that both ConceptNet's and word2vec's normalizations are applied to it.\n",
        "\n",
        "    'language' should be a BCP 47 language code, such as 'en' for English.\n",
        "\n",
        "    If the term already looks like a ConceptNet URI, it will only have its\n",
        "    sequences of digits replaced by #. Otherwise, it will be turned into a\n",
        "    ConceptNet URI in the given language, and then have its sequences of digits\n",
        "    replaced.\n",
        "    \"\"\"\n",
        "    if not (term.startswith('/') and term.count('/') >= 2):\n",
        "        term = _standardized_concept_uri(language, term)\n",
        "    return replace_numbers(term)\n",
        "\n",
        "\n",
        "def english_filter(tokens):\n",
        "    \"\"\"\n",
        "    Given a list of tokens, remove a small list of English stopwords. This\n",
        "    helps to work with previous versions of ConceptNet, which often provided\n",
        "    phrases such as 'an apple' and assumed they would be standardized to\n",
        "\t'apple'.\n",
        "    \"\"\"\n",
        "    non_stopwords = [token for token in tokens if token not in STOPWORDS]\n",
        "    while non_stopwords and non_stopwords[0] in DROP_FIRST:\n",
        "        non_stopwords = non_stopwords[1:]\n",
        "    if non_stopwords:\n",
        "        return non_stopwords\n",
        "    else:\n",
        "        return tokens\n",
        "\n",
        "\n",
        "def replace_numbers(s):\n",
        "    \"\"\"\n",
        "    Replace digits with # in any term where a sequence of two digits appears.\n",
        "\n",
        "    This operation is applied to text that passes through word2vec, so we\n",
        "    should match it.\n",
        "    \"\"\"\n",
        "    if DOUBLE_DIGIT_RE.search(s):\n",
        "        return DIGIT_RE.sub('#', s)\n",
        "    else:\n",
        "        return s\n",
        "\n",
        "\n",
        "def _standardized_concept_uri(language, term):\n",
        "    if language == 'en':\n",
        "        token_filter = english_filter\n",
        "    else:\n",
        "        token_filter = None\n",
        "    language = language.lower()\n",
        "    norm_text = _standardized_text(term, token_filter)\n",
        "    return '/c/{}/{}'.format(language, norm_text)\n",
        "    # return ''.format(language, norm_text)\n",
        "\n",
        "\n",
        "def _standardized_text(text, token_filter):\n",
        "    tokens = simple_tokenize(text.replace('_', ' '))\n",
        "    if token_filter is not None:\n",
        "        tokens = token_filter(tokens)\n",
        "    return '_'.join(tokens)\n",
        "\n",
        "\n",
        "def simple_tokenize(text):\n",
        "    \"\"\"\n",
        "    Tokenize text using the default wordfreq rules.\n",
        "    \"\"\"\n",
        "    return wordfreq.tokenize(text, 'xx')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bjDsyus2QsC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "embedding_dict = {}\n",
        "word_dict={}\n",
        "limit = 0\n",
        "with open(\"numberbatch-en.txt\", 'r') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], \"float32\")\n",
        "        embedding_dict[word] = vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjFBh63k2QsD"
      },
      "outputs": [],
      "source": [
        "#given a word, standardise it and return the embedding\n",
        "def get_embedding(word):\n",
        "    word = standardized_uri('en', word)\n",
        "    #truncate first 6 characters\n",
        "    word = word[6:]\n",
        "    if word in embedding_dict:\n",
        "        return embedding_dict[word]\n",
        "    else:\n",
        "        return np.ones(300, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mUXqqao2QsE"
      },
      "source": [
        "## DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YusBIXry2QsF",
        "outputId": "339c70d8-26d0-4443-fecb-dd0a83e819c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train size :  (20347, 7)\n",
            "test size :  (6116, 7)\n",
            "dev size :  (2733, 7)\n"
          ]
        }
      ],
      "source": [
        "df_train = pd.read_csv('WikiQACorpus/WikiQA-train.tsv', sep='\\t')\n",
        "df_train.head(30)\n",
        "\n",
        "df_test = pd.read_csv('WikiQACorpus/WikiQA-test.tsv', sep='\\t')\n",
        "df_test.head(30)\n",
        "\n",
        "df_dev = pd.read_csv('WikiQACorpus/WikiQA-dev.tsv', sep='\\t')\n",
        "df_dev.head(30)\n",
        "\n",
        "print(\"train size : \",df_train.shape)\n",
        "print(\"test size : \",df_test.shape)\n",
        "print(\"dev size : \",df_dev.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHqm3EAT2QsH"
      },
      "outputs": [],
      "source": [
        "# for each Question, sentence, remove special characters\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text\n",
        "\n",
        "df_train['Question'] = df_train['Question'].apply(lambda x: clean_text(x))\n",
        "df_train['Sentence'] = df_train['Sentence'].apply(lambda x: clean_text(x))\n",
        "\n",
        "df_dev['Question'] = df_dev['Question'].apply(lambda x: clean_text(x))\n",
        "df_dev['Sentence'] = df_dev['Sentence'].apply(lambda x: clean_text(x))\n",
        "\n",
        "df_test['Question'] = df_test['Question'].apply(lambda x: clean_text(x))\n",
        "df_test['Sentence'] = df_test['Sentence'].apply(lambda x: clean_text(x))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEitvowp2QsI"
      },
      "outputs": [],
      "source": [
        "#for each question, find the number of the words in the question\n",
        "def get_question_length(row):\n",
        "    return len(row['Question'].split())\n",
        "\n",
        "def get_sentence_length(row):\n",
        "    return len(row['Sentence'].split())\n",
        "\n",
        "df_train['Question_length'] = df_train.apply(get_question_length, axis=1)\n",
        "df_train['Candidate_length'] = df_train.apply(get_sentence_length, axis=1)\n",
        "df_train = df_train.drop(['DocumentID', 'DocumentTitle', 'SentenceID'], axis=1)\n",
        "\n",
        "df_test['Question_length'] = df_test.apply(get_question_length, axis=1)\n",
        "df_test['Candidate_length'] = df_test.apply(get_sentence_length, axis=1)\n",
        "df_test = df_test.drop(['DocumentID', 'DocumentTitle', 'SentenceID'], axis=1)\n",
        "\n",
        "df_dev['Question_length'] = df_dev.apply(get_question_length, axis=1)\n",
        "df_dev['Candidate_length'] = df_dev.apply(get_sentence_length, axis=1)\n",
        "df_dev = df_dev.drop(['DocumentID', 'DocumentTitle', 'SentenceID'], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw4zV96K2QsJ",
        "outputId": "c8fb47b1-5186-41c0-aa62-8107bab6ad35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max question length in train data set:  23\n",
            "Max candidate length in train data set:  305\n",
            "Number of unique questions in train data set:  2117\n",
            "Total number of candidates in train data set:  20347\n"
          ]
        }
      ],
      "source": [
        "# find the maximum length of the question and the candidate sentence\n",
        "max_question_length = df_train['Question_length'].max()\n",
        "max_candidate_length = df_train['Candidate_length'].max()\n",
        "#find the number of unique questions \n",
        "unique_questions = df_train['QuestionID'].unique()\n",
        "print(\"Max question length in train data set: \", max_question_length)\n",
        "print(\"Max candidate length in train data set: \", max_candidate_length)\n",
        "print(\"Number of unique questions in train data set: \", len(unique_questions))\n",
        "\n",
        "total_candidates = len(df_train)\n",
        "print(\"Total number of candidates in train data set: \", total_candidates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va4sNbYU2QsJ",
        "outputId": "d355e4f2-fa82-4d16-aaac-39ef8a9ad4c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train size :  (20347, 6)\n",
            "test size :  (6115, 6)\n",
            "dev size :  (2733, 6)\n"
          ]
        }
      ],
      "source": [
        "# delete the row if sentence length is greater than 50 and label is 0\n",
        "\n",
        "df_train = df_train.drop(df_train[(df_train['Label'] == 0) & (df_train['Candidate_length'] > CANDIDATE_LEN)].index)\n",
        "df_test = df_test.drop(df_test[(df_test['Label'] == 0) & (df_test['Candidate_length'] > CANDIDATE_LEN)].index)\n",
        "df_dev = df_dev.drop(df_dev[(df_dev['Label'] == 0) & (df_dev['Candidate_length'] > CANDIDATE_LEN)].index)\n",
        "\n",
        "\n",
        "\n",
        "print(\"train size : \",df_train.shape)\n",
        "print(\"test size : \",df_test.shape)\n",
        "print(\"dev size : \",df_dev.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9XIklpa2QsK",
        "outputId": "e562bf75-4426-4ae5-bad8-b113e96155a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique questions in train data set:  2117\n",
            "Number of unique questions in test data set:  630\n",
            "Number of unique questions in dev data set:  296\n"
          ]
        }
      ],
      "source": [
        "QuestionID_greater_than_CANDIDATE_LEN = []\n",
        "\n",
        "# for candidate if length is greater than CANDIDATE_LEN, add the question id to the list\n",
        "for index, row in df_train.iterrows():\n",
        "    if row['Candidate_length'] > CANDIDATE_LEN:\n",
        "        QuestionID_greater_than_CANDIDATE_LEN.append(row['QuestionID'])\n",
        "\n",
        "# delete the rows where the question id is in the list\n",
        "df_train = df_train[~df_train['QuestionID'].isin(QuestionID_greater_than_CANDIDATE_LEN)]\n",
        "\n",
        "#print the nubmer of unique questions\n",
        "unique_questions = df_train['QuestionID'].unique()\n",
        "print(\"Number of unique questions in train data set: \", len(unique_questions))\n",
        "\n",
        "\n",
        "QuestionID_greater_than_CANDIDATE_LEN = []\n",
        "\n",
        "# for candidate if length is greater than CANDIDATE_LEN, add the question id to the list\n",
        "for index, row in df_test.iterrows():\n",
        "    if row['Candidate_length'] > CANDIDATE_LEN:\n",
        "        QuestionID_greater_than_CANDIDATE_LEN.append(row['QuestionID'])\n",
        "\n",
        "# delete the rows where the question id is in the list\n",
        "df_test = df_test[~df_test['QuestionID'].isin(QuestionID_greater_than_CANDIDATE_LEN)]\n",
        "\n",
        "#print the nubmer of unique questions\n",
        "unique_questions = df_test['QuestionID'].unique()\n",
        "print(\"Number of unique questions in test data set: \", len(unique_questions))\n",
        "\n",
        "QuestionID_greater_than_CANDIDATE_LEN = []\n",
        "\n",
        "# for candidate if length is greater than CANDIDATE_LEN, add the question id to the list\n",
        "for index, row in df_dev.iterrows():\n",
        "    if row['Candidate_length'] > CANDIDATE_LEN:\n",
        "        QuestionID_greater_than_CANDIDATE_LEN.append(row['QuestionID'])\n",
        "\n",
        "# delete the rows where the question id is in the list\n",
        "df_dev = df_dev[~df_dev['QuestionID'].isin(QuestionID_greater_than_CANDIDATE_LEN)]\n",
        "\n",
        "#print the nubmer of unique questions\n",
        "unique_questions = df_dev['QuestionID'].unique()\n",
        "print(\"Number of unique questions in dev data set: \", len(unique_questions))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKvtTRgf2QsL",
        "outputId": "dd00283f-b0fa-4e9f-abeb-b60d1941ce05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max question length in train dataset:  23\n",
            "Max candidate length in train dataset:  305\n",
            "Max question length in test dataset:  19\n",
            "Max candidate length in test dataset:  132\n",
            "Max question length in dev dataset:  21\n",
            "Max candidate length in dev dataset:  120\n"
          ]
        }
      ],
      "source": [
        "# dind the maximum length of the question and the candidate sentence\n",
        "max_question_length = df_train['Question_length'].max()\n",
        "max_candidate_length = df_train['Candidate_length'].max()\n",
        "\n",
        "print(\"Max question length in train dataset: \", max_question_length)\n",
        "print(\"Max candidate length in train dataset: \", max_candidate_length)\n",
        "\n",
        "# dind the maximum length of the question and the candidate sentence\n",
        "max_question_length = df_test['Question_length'].max()\n",
        "max_candidate_length = df_test['Candidate_length'].max()\n",
        "\n",
        "print(\"Max question length in test dataset: \", max_question_length)\n",
        "print(\"Max candidate length in test dataset: \", max_candidate_length)\n",
        "\n",
        "# dind the maximum length of the question and the candidate sentence\n",
        "max_question_length = df_dev['Question_length'].max()\n",
        "max_candidate_length = df_dev['Candidate_length'].max()\n",
        "\n",
        "print(\"Max question length in dev dataset: \", max_question_length)\n",
        "print(\"Max candidate length in dev dataset: \", max_candidate_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay__kaK02QsL"
      },
      "outputs": [],
      "source": [
        "# reformat the data where each question has a list of candidate sentences and a list of labels\n",
        "# 1 if the sentence is the answer, 0 otherwise\n",
        "def reformat_data(df):\n",
        "    questions = []\n",
        "    candidates = []\n",
        "    labels = []\n",
        "    for index, row in df.iterrows():\n",
        "        if row['Question'] not in questions:\n",
        "            questions.append(row['Question'])\n",
        "            candidates.append([row['Sentence']])\n",
        "            labels.append([row['Label']])\n",
        "        else:\n",
        "            candidates[questions.index(row['Question'])].append(row['Sentence'])\n",
        "            labels[questions.index(row['Question'])].append(row['Label'])\n",
        "    return questions, candidates, labels\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ck00yyj2QsL",
        "outputId": "8f54b2dc-8ce5-418c-d0c9-c767cd618a14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23\n",
            "503\n"
          ]
        }
      ],
      "source": [
        "text_questions_train, text_candidates_train, labels_train = reformat_data(df_train)\n",
        "text_questions_test, text_candidates_test, labels_test = reformat_data(df_test)\n",
        "text_questions_dev, text_candidates_dev, labels_dev = reformat_data(df_dev)\n",
        "\n",
        "max_question_length = QUESTION_LEN\n",
        "max_candidate_length = CANDIDATE_LEN\n",
        "print(max_question_length)\n",
        "print(max_candidate_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5GpLKiw2QsM"
      },
      "outputs": [],
      "source": [
        "emb_questions_train = []\n",
        "emb_candidates_train = []\n",
        "\n",
        "# get the embedding for each word in the question and candidate sentence using the get_embedding function\n",
        "for question in text_questions_train:\n",
        "    emb_questions_train.append([get_embedding(word) for word in question.split()])\n",
        "for candidate in text_candidates_train:\n",
        "    emb_candidates_train.append([[get_embedding(word) for word in sentence.split()] for sentence in candidate])\n",
        "\n",
        "emb_questions_test = []\n",
        "emb_candidates_test = []\n",
        "\n",
        "# get the embedding for each word in the question and candidate sentence using the get_embedding function\n",
        "for question in text_questions_test:\n",
        "    emb_questions_test.append([get_embedding(word) for word in question.split()])\n",
        "for candidate in text_candidates_test:\n",
        "    emb_candidates_test.append([[get_embedding(word) for word in sentence.split()] for sentence in candidate])\n",
        "\n",
        "emb_questions_dev = []\n",
        "emb_candidates_dev = []\n",
        "\n",
        "# get the embedding for each word in the question and candidate sentence using the get_embedding function\n",
        "for question in text_questions_dev:\n",
        "    emb_questions_dev.append([get_embedding(word) for word in question.split()])\n",
        "for candidate in text_candidates_dev:\n",
        "    emb_candidates_dev.append([[get_embedding(word) for word in sentence.split()] for sentence in candidate])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTBPDvrn2QsM",
        "outputId": "0b41d2d4-f9ae-4f78-b72b-fd9ac119a845"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of candidates train dataset:  20347\n",
            "Total number of questions train dataset:  2117\n"
          ]
        }
      ],
      "source": [
        "# print the total number of candidates for all questions\n",
        "total_candidates_train = 0\n",
        "for candidate in emb_candidates_train:\n",
        "    total_candidates_train += len(candidate)\n",
        "print(\"Total number of candidates train dataset: \", total_candidates_train)\n",
        "\n",
        "print(\"Total number of questions train dataset: \", len(emb_questions_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mMtTr7L2QsN",
        "outputId": "60562617-0a83-47df-8bc3-864310883e0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of candidates in train dataset:  8666\n",
            "Total number of questions in train dataset:  872\n"
          ]
        }
      ],
      "source": [
        "# if all the labels are zero, remove the question and candidate sentence\n",
        "def remove_all_zeros(labels,emb_questions,emb_candidates):\n",
        "  for i in range(len(labels)):\n",
        "      if sum(labels[i]) == 0:\n",
        "          emb_questions[i] = []\n",
        "          emb_candidates[i] = []\n",
        "          labels[i] = []\n",
        "\n",
        "  # remove the empty lists\n",
        "  return [x for x in emb_questions if x != []] ,[x for x in emb_candidates if x != []] ,[x for x in labels if x != []]\n",
        "\n",
        "emb_questions_train,emb_candidates_train,labels_train = remove_all_zeros(labels_train,emb_questions_train,emb_candidates_train)\n",
        "emb_questions_test,emb_candidates_test,labels_test = remove_all_zeros(labels_test,emb_questions_test,emb_candidates_test)\n",
        "emb_questions_dev,emb_candidates_dev,labels_dev = remove_all_zeros(labels_dev,emb_questions_dev,emb_candidates_dev)\n",
        "\n",
        "# print the total number of candidates for all questions\n",
        "total_candidates = 0\n",
        "for candidate in emb_candidates_train:\n",
        "    total_candidates += len(candidate)\n",
        "print(\"Total number of candidates in train dataset: \", total_candidates)\n",
        "\n",
        "print(\"Total number of questions in train dataset: \", len(emb_questions_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5uCd7ZJ2QsN"
      },
      "outputs": [],
      "source": [
        "# for each question, candiate sentence pair, perform a cosinet between each embedding of question to each embedding of sentence to identify the most similar word\n",
        "\n",
        "def get_cosine_similarity(emb_question, emb_candidate):\n",
        "    question_cosines = []\n",
        "    candidate_cosines = []\n",
        "    # for each word in question, find the word in the candidate sentence that is most similar and calculate the maximum cosine similarity\n",
        "    for word in emb_question:\n",
        "        question_cosines.append(max([np.dot(word, candidate_word)/(np.linalg.norm(word)*np.linalg.norm(candidate_word)) for candidate_word in emb_candidate]))\n",
        "        \n",
        "\n",
        "    for word in emb_candidate:\n",
        "        candidate_cosines.append(max([np.dot(word, question_word)/(np.linalg.norm(word)*np.linalg.norm(question_word)) for question_word in emb_question]))\n",
        "        \n",
        "\n",
        "    return question_cosines, candidate_cosines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jH_LpbIv2QsN"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "def embeddings_q_c_l(emb_questions,emb_candidates,labels):\n",
        "  r_emb_question_candidate_pairs = []\n",
        "\n",
        "\n",
        "  # for each question, candidate sentence pair, get the cosine similarity between each word in the question and each word in the candidate sentence\n",
        "  # append the cosine similarity values to each question and candidate sentence embedding\n",
        "  for i in range(len(emb_questions)):\n",
        "      temp = []\n",
        "      for j in range(len(emb_candidates[i])):\n",
        "          question_cosines, candidate_cosines = get_cosine_similarity(emb_questions[i], emb_candidates[i][j])\n",
        "\n",
        "          # take a deep copy of emb_question[i]\n",
        "          temp_emb_question = copy.deepcopy(emb_questions[i])\n",
        "          temp_emb_candidate = copy.deepcopy(emb_candidates[i][j])\n",
        "          for k in range(len(temp_emb_question)):\n",
        "              temp_emb_question[k] = np.append(temp_emb_question[k], question_cosines[k])\n",
        "          for k in range(len(temp_emb_candidate)):\n",
        "              temp_emb_candidate[k] = np.append(temp_emb_candidate[k], candidate_cosines[k])\n",
        "          temp.append([temp_emb_question, temp_emb_candidate, labels[i][j]])\n",
        "      r_emb_question_candidate_pairs.append(temp)\n",
        "  return r_emb_question_candidate_pairs\n",
        "\n",
        "r_emb_question_candidate_pairs_train = embeddings_q_c_l(emb_questions_train,emb_candidates_train,labels_train)\n",
        "r_emb_question_candidate_pairs_test = embeddings_q_c_l(emb_questions_test,emb_candidates_test,labels_test)\n",
        "r_emb_question_candidate_pairs_dev = embeddings_q_c_l(emb_questions_dev,emb_candidates_dev,labels_dev)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GW9Cmarv2QsO"
      },
      "outputs": [],
      "source": [
        "#pad the sentence based on given required length from the r_emb_question_candidate_pairs\n",
        "def pad_sentence_embedding(sentence_embedding, required_length):\n",
        "\n",
        "    if len(sentence_embedding) < required_length:\n",
        "        for i in range(required_length - len(sentence_embedding)):\n",
        "            sentence_embedding.append(np.zeros(len(sentence_embedding[0])))\n",
        "\n",
        "    return sentence_embedding\n",
        "\n",
        "\n",
        "# pad the question and candidate sentence embedding based on the max length of the question and candidate sentence\n",
        "def get_pr_emb_question_candidate_pairs(r_emb_question_candidate_pairs):\n",
        "  pr_emb_question_candidate_pairs = []\n",
        "  for entry in r_emb_question_candidate_pairs:\n",
        "      temp = []\n",
        "      for question, candidate, label in entry:\n",
        "          temp.append([pad_sentence_embedding(question, max_question_length), pad_sentence_embedding(candidate, max_candidate_length), label])\n",
        "      pr_emb_question_candidate_pairs.append(temp)\n",
        "  return pr_emb_question_candidate_pairs\n",
        "\n",
        "pr_emb_question_candidate_pairs_train = get_pr_emb_question_candidate_pairs(r_emb_question_candidate_pairs_train)\n",
        "pr_emb_question_candidate_pairs_test = get_pr_emb_question_candidate_pairs(r_emb_question_candidate_pairs_test)\n",
        "pr_emb_question_candidate_pairs_dev = get_pr_emb_question_candidate_pairs(r_emb_question_candidate_pairs_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfysHX5T2QsP"
      },
      "outputs": [],
      "source": [
        "#find the number of candidates for each question\n",
        "# num_candidates = []\n",
        "# for i in range(len(r_emb_question_candidate_pairs)):\n",
        "#     num_candidates.append(len(r_emb_question_candidate_pairs[i]))\n",
        "\n",
        "\n",
        "# # max number of candidates for a question\n",
        "# max_num_candidates = max(num_candidates)\n",
        "\n",
        "# # generate a dummy candidate with padding = max_candidate_length by using <PAD> tokens\n",
        "# dummy_candidate = []\n",
        "# for i in range(max_candidate_length):\n",
        "#     dummy_candidate.append(np.zeros(len(sample_candidate[0])))\n",
        "\n",
        "# # pad the candidate sentence embedding with dummy candidate\n",
        "# for i in range(len(pr_emb_question_candidate_pairs)):\n",
        "#     if len(pr_emb_question_candidate_pairs[i]) < max_num_candidates:\n",
        "#         pr_emb_question_candidate_pairs[i].extend([[pr_emb_question_candidate_pairs[i][0][0], dummy_candidate, 0]]*(max_num_candidates - len(pr_emb_question_candidate_pairs[i])))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JLPQV1K2QsP"
      },
      "outputs": [],
      "source": [
        "# change every list into a numpy array\n",
        "for i in range(len(pr_emb_question_candidate_pairs_train)):\n",
        "    for j in range(len(pr_emb_question_candidate_pairs_train[i])):\n",
        "        pr_emb_question_candidate_pairs_train[i][j][0] = np.asarray(pr_emb_question_candidate_pairs_train[i][j][0], dtype=np.float32)\n",
        "        pr_emb_question_candidate_pairs_train[i][j][1] = np.asarray(pr_emb_question_candidate_pairs_train[i][j][1], dtype=np.float32)\n",
        "\n",
        "for i in range(len(pr_emb_question_candidate_pairs_test)):\n",
        "    for j in range(len(pr_emb_question_candidate_pairs_test[i])):\n",
        "        pr_emb_question_candidate_pairs_test[i][j][0] = np.asarray(pr_emb_question_candidate_pairs_test[i][j][0], dtype=np.float32)\n",
        "        pr_emb_question_candidate_pairs_test[i][j][1] = np.asarray(pr_emb_question_candidate_pairs_test[i][j][1], dtype=np.float32)\n",
        "\n",
        "for i in range(len(pr_emb_question_candidate_pairs_dev)):\n",
        "    for j in range(len(pr_emb_question_candidate_pairs_dev[i])):\n",
        "        pr_emb_question_candidate_pairs_dev[i][j][0] = np.asarray(pr_emb_question_candidate_pairs_dev[i][j][0], dtype=np.float32)\n",
        "        pr_emb_question_candidate_pairs_dev[i][j][1] = np.asarray(pr_emb_question_candidate_pairs_dev[i][j][1], dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqaXvHCV2QsP"
      },
      "outputs": [],
      "source": [
        "# find the shape of the question and candidate sentence embedding\n",
        "# print the number of questions and number of candidates for each question\n",
        "print(\"Shape of question embedding: \", pr_emb_question_candidate_pairs_train[0][0][0].shape)\n",
        "print(\"Shape of candidate embedding: \", pr_emb_question_candidate_pairs_train[0][0][1].shape)\n",
        "print(\"Number of questions: \", len(pr_emb_question_candidate_pairs_train))\n",
        "print(\"Number of Questions: \", len(pr_emb_question_candidate_pairs_train))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L9fII8JW5iZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWr6-bwP2QsQ"
      },
      "outputs": [],
      "source": [
        "# save list as a pickle file and load\n",
        "import pickle\n",
        "\n",
        "def save_pickle(obj, path):\n",
        "    with open(path, 'wb') as f:\n",
        "        pickle.dump(obj, f)\n",
        "\n",
        "def load_pickle(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        return pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ko-i-Ppz2QsQ"
      },
      "outputs": [],
      "source": [
        "save_pickle(pr_emb_question_candidate_pairs_train,'./qc_embeddings_train_paper1.pkl')\n",
        "save_pickle(pr_emb_question_candidate_pairs_test,'./qc_embeddings_test_paper1.pkl')\n",
        "save_pickle(pr_emb_question_candidate_pairs_dev,'./qc_embeddings_dev_paper1.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3_HigJ-NbiGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/NLP-Project/data"
      ],
      "metadata": {
        "id": "Q_komxd1bjC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load a pickle file to a list\n",
        "import pickle\n",
        "# load a pickle file to a list\n",
        "import pickle\n",
        "def load_pickle(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "def load_pickle(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "pr_emb_question_candidate_pairs_train = load_pickle(\"qc_embeddings_train_paper1.pkl\")\n",
        "pr_emb_question_candidate_pairs_test = load_pickle(\"qc_embeddings_test_paper1.pkl\")\n",
        "pr_emb_question_candidate_pairs_dev = load_pickle(\"qc_embeddings_dev_paper1.pkl\")"
      ],
      "metadata": {
        "id": "K1E5PWclbU-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "mFI4jJPAcCxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert pr_emb_question_candidate_pairs to list of question_embedding, candidate_embedding, label\n",
        "\n",
        "# list of question_embedding, candidate_embedding, label\n",
        "def convert_to_qcl(pr_emb_question_candidate_pairs):\n",
        "  qcl = []\n",
        "\n",
        "  for i in range(len(pr_emb_question_candidate_pairs)):\n",
        "      for j in range(len(pr_emb_question_candidate_pairs[i])):\n",
        "          qcl.append([np.array(pr_emb_question_candidate_pairs[i][j][0]), np.array(pr_emb_question_candidate_pairs[i][j][1]), np.array(pr_emb_question_candidate_pairs[i][j][2])])\n",
        "  return qcl\n",
        "\n",
        "qcl_train = convert_to_qcl(pr_emb_question_candidate_pairs_train)\n",
        "qcl_test = convert_to_qcl(pr_emb_question_candidate_pairs_test)\n",
        "qcl_dev = convert_to_qcl(pr_emb_question_candidate_pairs_dev)\n",
        "\n",
        "def seperate_qcl(qcl):\n",
        "  questions_emb = []\n",
        "  candidates_emb = []\n",
        "  labels = []\n",
        "\n",
        "  for i in range(len(qcl)):\n",
        "      questions_emb.append(qcl[i][0])\n",
        "      candidates_emb.append(qcl[i][1])\n",
        "      labels.append(qcl[i][2])\n",
        "\n",
        "\n",
        "  questions_emb = np.array(questions_emb)\n",
        "  candidates_emb = np.array(candidates_emb)\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return questions_emb,candidates_emb,labels\n",
        "\n",
        "questions_emb_train,candidates_emb_train,labels_train = seperate_qcl(qcl_train)\n",
        "questions_emb_test,candidates_emb_test,labels_test = seperate_qcl(qcl_test)\n",
        "questions_emb_dev,candidates_emb_dev,labels_dev = seperate_qcl(qcl_dev)\n"
      ],
      "metadata": {
        "id": "aUd0dVMnXfCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_train.shape"
      ],
      "metadata": {
        "id": "kgup8KVzYyoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data_utils\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "import random\n",
        "\n",
        "class CNN_RNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_RNN, self).__init__()\n",
        "        # question size (301,32)\n",
        "        # candidate size (301,64)\n",
        "        \n",
        "        # apply conv2d on question embedding with kernel size 5\n",
        "        self.conv1 = nn.Conv2d(1, 1, 5)\n",
        "        # apply conv2d on candidate embedding with kernel size 5\n",
        "        self.conv2 = nn.Conv2d(1, 1, 5)\n",
        "\n",
        "        # output size of conv1 = (301-5+1, 32-5+1) = (297, 28)\n",
        "        # output size of conv2 = (301-5+1, 64-5+1) = (297, 60)\n",
        "\n",
        "        # apply global max pooling along such that the size is (297,1)\n",
        "        self.pool1 = nn.MaxPool2d((1, QUESTION_LEN-5+1))\n",
        "        self.pool2 = nn.MaxPool2d((1, CANDIDATE_LEN-5+1))\n",
        "\n",
        "        # output size of pool1 = (297,1)\n",
        "        # output size of pool2 = (297,1)\n",
        "\n",
        "        # concatenate the output of pool1 and pool2 \n",
        "        # output size of concat = (297+297, 1) = (594, 1)\n",
        "\n",
        "        # apply RNN on the concatenated output\n",
        "        self.rnn = nn.RNN(594, 594, 1, batch_first=True)\n",
        "\n",
        "        # classify the output of RNN as two classes\n",
        "        self.fc = nn.Linear(594, 2)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,q,c):\n",
        "        # q = q.view(-1, 1, 301, 32)\n",
        "        # c = c.view(-1, 1, 301, 64)\n",
        "        q = q.view(-1, 1, 301, QUESTION_LEN)\n",
        "        c = c.view(-1, 1, 301, CANDIDATE_LEN)\n",
        "        q = F.relu(self.conv1(q))\n",
        "        c = F.relu(self.conv2(c))\n",
        "        q = self.pool1(q)\n",
        "        c = self.pool2(c)\n",
        "        q = q.view(-1, 297)\n",
        "        c = c.view(-1, 297)\n",
        "        mul = torch.mul(q,c)\n",
        "        sub = torch.sub(q,c)\n",
        "        x = torch.cat((mul,sub),1)\n",
        "        # x size = (1, 594)\n",
        "        x = x.view(-1, 1, 594)\n",
        "        x, _ = self.rnn(x)\n",
        "        x = x.view(-1, 594)\n",
        "        x = self.fc(x)\n",
        "        # x size = (-1, 2)\n",
        "        return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UlvoTHf96EOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model with batc size of 64\n",
        "from tqdm import trange\n",
        "def train(qcl,questions_emb,candidates_emb,labels,epochs=3):\n",
        "  # define the model\n",
        "  model = CNN_RNN()\n",
        "  # define the loss function\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  # define the optimizer\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  # train the model on qcl ( question_embedding, candidate_embedding, label)\n",
        "\n",
        "  for epoch in trange(epochs,desc='Epochs'):  # loop over the dataset multiple times\n",
        "      running_loss = []\n",
        "      for i in range(0,len(qcl),64):\n",
        "      \n",
        "          questions = questions_emb[i:i+64]\n",
        "          candidates = candidates_emb[i:i+64]\n",
        "          labels_64 = labels[i:i+64]\n",
        "\n",
        "\n",
        "          # shape of question = (64, 301, 32)\n",
        "          # shape of candidate = (64, 301, 64)\n",
        "          # shape of label = (64,)\n",
        "          \n",
        "          # convert question to numpy array and change the size to (64,32,301)\n",
        "\n",
        "          questions = questions.reshape(-1,QUESTION_LEN,301)\n",
        "          # convert candidate to numpy array and change the size to (64,64,301)\n",
        "          candidates = candidates.reshape(-1,CANDIDATE_LEN,301)\n",
        "\n",
        "          # convert question to torch tensor\n",
        "          questions = torch.from_numpy(questions)\n",
        "          # convert candidates to torch tensor\n",
        "          candidates = torch.from_numpy(candidates)\n",
        "          # convert label to torch tensor\n",
        "\n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # forward + backward + optimize\n",
        "          outputs = model(questions, candidates)\n",
        "          loss = criterion(outputs, torch.from_numpy(labels_64))\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # print statistics\n",
        "          running_loss.append(loss.item())\n",
        "\n",
        "      print(f\"Epoch : {epoch} , loss : {np.mean(running_loss)}\")    \n",
        "  return model"
      ],
      "metadata": {
        "id": "BiVgX9HGXahm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metric(model,pr_emb_question_candidate_pairs):\n",
        "    model.eval()\n",
        "\n",
        "    precisions = []\n",
        "    ranks = []\n",
        "\n",
        "\n",
        "    # extract question and candidate embeddings\n",
        "    for q in pr_emb_question_candidate_pairs:\n",
        "        real_labels = []\n",
        "        predicted_scores = []\n",
        "        for c_ind,c in enumerate(q):\n",
        "            \n",
        "\n",
        "            candidate_embedding = np.array(c[1])\n",
        "            real_labels.append(c[2])\n",
        "            # shape of qe = (1, 301, 32)\n",
        "            # shape of c = (1, 301, 64)\n",
        "            q_emb = np.array(c[0])\n",
        "            q_emb = q_emb.reshape(1,QUESTION_LEN,301)\n",
        "            candidate_embedding = candidate_embedding.reshape(1,CANDIDATE_LEN,301)\n",
        "            # convert q_emb to torch tensor\n",
        "            q_emb = torch.from_numpy(q_emb)\n",
        "            # convert c to torch tensor\n",
        "            candidate_embedding = torch.from_numpy(candidate_embedding)\n",
        "            # forward\n",
        "            outputs = model(q_emb, candidate_embedding)\n",
        "            outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "            # convert outputs to numpy array\n",
        "            outputs = outputs.detach().numpy()\n",
        "            predicted_scores.append(outputs)\n",
        "\n",
        "        \n",
        "        real_labels = np.array(real_labels)\n",
        "        question_real_labels_indices = np.where(real_labels == 1)[0]\n",
        "        predicted_scores = np.array(predicted_scores)\n",
        "        # print(predicted_scores.shape)\n",
        "        predicted_scores = predicted_scores.squeeze(axis=1)\n",
        "        # print(predicted_scores.shape)\n",
        "        predicted_scores = predicted_scores[:,1] - predicted_scores[:,0]\n",
        "        predicted_scores = np.array(predicted_scores)\n",
        "        sorted_indices = np.argsort(predicted_scores)\n",
        "        sorted_indices = sorted_indices[::-1]\n",
        "        for i in range(len(sorted_indices)):\n",
        "            if sorted_indices[i] in question_real_labels_indices:\n",
        "                sorted_indices[i] = -1\n",
        "\n",
        "        precision = 0\n",
        "        rank = 0\n",
        "        c = 0\n",
        "        for i,ind in enumerate(sorted_indices):\n",
        "            if ind == -1:\n",
        "                rank = 1/(i+1)\n",
        "                c += 1\n",
        "                precision += (c/(i+1))\n",
        "        \n",
        "        \n",
        "        \n",
        "        precision = precision/c\n",
        "        precisions.append(precision)\n",
        "        ranks.append(rank)\n",
        "    \n",
        "\n",
        "        \n",
        "    model.train()\n",
        "    return np.mean(precisions), np.mean(ranks)"
      ],
      "metadata": {
        "id": "aspLxVu5jauN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = train(qcl_train,questions_emb_train,candidates_emb_train,labels_train,3)"
      ],
      "metadata": {
        "id": "ttnGFaS70XhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_MAP, train_MRR = metric(model_3,pr_emb_question_candidate_pairs_train)\n",
        "print(\"train MAP : \",train_MAP)\n",
        "print(\"train MRR : \",train_MRR)"
      ],
      "metadata": {
        "id": "dBvlmHUOX-VX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pr_emb_question_candidate_pairs_test[0][0][1].shape"
      ],
      "metadata": {
        "id": "Z2XtulzT1FUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_MAP, test_MRR = metric(model_3,pr_emb_question_candidate_pairs_test)\n",
        "print(\"test MAP : \",test_MAP)\n",
        "print(\"test MRR : \",test_MRR)"
      ],
      "metadata": {
        "id": "4kHOSm9dbzhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODELS = []\n",
        "TRAIN_MAPS = []\n",
        "TRAIN_MRRS = []\n",
        "TEST_MAPS = []\n",
        "TEST_MRRS = []\n",
        "\n",
        "for epoch in range(1,11):\n",
        "  print(\"Currently EPOCH IS \", epoch)\n",
        "  print(\" \")\n",
        "  temp_model = train(qcl_train,questions_emb_train,candidates_emb_train,labels_train,epoch)\n",
        "  train_MAP, train_MRR = metric(temp_model,pr_emb_question_candidate_pairs_train)\n",
        "  TRAIN_MAPS.append(train_MAP)\n",
        "  TRAIN_MRRS.append(train_MRR)\n",
        "\n",
        "\n",
        "  test_MAP, test_MRR = metric(temp_model,pr_emb_question_candidate_pairs_test)\n",
        "  print(\"For epoch \" + str(epoch) + \": train MAP : \" + str(train_MAP) + \" train MRR : \" + str(train_MRR) )\n",
        "  print(\"For epoch \" + str(epoch) + \": test MAP : \" + str(test_MAP) + \" test MRR : \" + str(test_MRR) )\n",
        "  print(\" \")\n",
        "  MODELS.append(temp_model)\n",
        "  TEST_MAPS.append(test_MAP)\n",
        "  TEST_MRRS.append(test_MRR)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "awj7gA870uvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_pickle(TRAIN_MAPS,'./23-503-train_maps.pkl')\n",
        "save_pickle(TRAIN_MRRS,'./23-503-train_mrrs.pkl')\n",
        "save_pickle(TEST_MAPS,'./23-503-test_maps.pkl')\n",
        "save_pickle(TEST_MRRS,'./23-503-test_mrrs.pkl')"
      ],
      "metadata": {
        "id": "u25Tj2q-RL4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_MAPS=load_pickle('./train_maps.pkl')\n",
        "TRAIN_MRRS=load_pickle('./train_mrrs.pkl')\n",
        "TEST_MAPS=load_pickle('./test_maps.pkl')\n",
        "TEST_MRRS=load_pickle('./test_mrrs.pkl')\n",
        "\n",
        "new_TRAIN_MAPS=load_pickle('./23-503-train_maps.pkl')\n",
        "new_TRAIN_MRRS=load_pickle('./23-503-train_mrrs.pkl')\n",
        "new_TEST_MAPS=load_pickle('./23-503-test_maps.pkl')\n",
        "new_TEST_MRRS=load_pickle('./23-503-test_mrrs.pkl')"
      ],
      "metadata": {
        "id": "OkzdC0ejJe_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xpoints = [i for i in range(1,11)]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.plot(xpoints, new_TRAIN_MAPS, label=\"new_Train Map\")\n",
        "# plt.plot(xpoints, TRAIN_MAPS, label=\"Train Map\")\n",
        "plt.plot(xpoints, new_TEST_MAPS, label = \"new_Test Map\")\n",
        "plt.plot(xpoints, TEST_MAPS, label = \"Test Map\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "J7w2twwuQ5ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(xpoints, new_TRAIN_MRRS, label=\"new_Train MRR\")\n",
        "plt.plot(xpoints, TRAIN_MRRS, label=\"Train MRR\")\n",
        "plt.plot(xpoints, new_TEST_MRRS, label = \"new_Test MRR\")\n",
        "plt.plot(xpoints, TEST_MRRS, label = \"Test MRR\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8nPtjLmKKhA1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e98dfee42324e78eea15aaf0cd33c66aa32b8af464e8601118066cc2ac43fff9"
      }
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}